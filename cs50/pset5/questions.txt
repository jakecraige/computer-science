0.  It's a word that refers to a lung disease that's also the longest word in the dictionary.
1.  Returns the resource usage of the given "who"
2.  16
3.  The struct is large and takes up a lot of memory so we don't want to incur the cost of copying that.
4.  It iterates over the text a character at a time until it finds a full word. When it does, it runs
    it through the spell checker and prints the result. It finds words by checking that the given
    character is an alpha or an apostrophe not at the beginning of a word, if so, it stores that
    character in the word string and increments the index. If the words is longer than the LENGTH
    it consumes the rest of the word and resets the index to start looking for a new word. If the
    given character is a number it will also consume the rest because numbers aren't allowed.
5.  TODO: Why fgetc and not fscanf? You can't be specific enough with fscanf?
6.  It specifies to the user and compiler that these values shouldn't be changed.
7.  I used a hash table that's hashed by the sum of the first 20 characters. The
    nodes are stored as a linked list so each node has a pointer to it's next node and a value.
8.  The check was pretty slow because there were only 26 possible hashes so the linked lists
    grew large and were slow to iterate over.
9.  I extended the hashing method to have more possible outcomes which makes the
    linked lists shorter so it takes less time to iterate over them.
10. I think if I had a better hashing function it's possible the lookups would
    be quicker since that's the bottleneck. I also could have implemented it as a
    trie which would have had a more efficient lookup.
